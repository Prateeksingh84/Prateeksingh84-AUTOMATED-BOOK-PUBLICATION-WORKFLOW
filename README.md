ğŸ“š Automated Book Publication Workflow

LLM-powered pipeline that simulates a modern book-publishing flowâ€”from web scraping chapters to AI rewriting, AI review, human approval, and versioned storage for publication.

Stack: Python 3.10+, Google Gemini (Generative AI), ChromaDB, SentenceTransformer, AsyncIO

ğŸš€ Features

Web Scraping: Fetch chapter content from a URL (e.g., Wikisource) or use local files

AI Writing Agent: Creative rewrites via Gemini with configurable prompts

AI Reviewing Agent: Compares original vs. AI rewrite and gives structured feedback

Human-in-the-Loop: Approve or edit drafts before finalization

Version Control: Store original, AI drafts, human edits in ChromaDB with metadata + semantic search

Reproducibility: Saves prompt history, run logs, and outputs

ğŸ—‚ï¸ Project Structure

project/
â”œâ”€ main.py                     # Orchestrates the full workflow
â”œâ”€ prompts/
â”‚  â”œâ”€ extraction_prompt.txt    # Content extraction / structuring
â”‚  â””â”€ review_prompt.txt        # Editorial review prompt
â”œâ”€ utils/
â”‚  â”œâ”€ pdf_parser.py
â”‚  â”œâ”€ web_scraper.py
â”‚  â”œâ”€ ai_writer.py             # Gemini interface (writer)
â”‚  â”œâ”€ ai_reviewer.py           # Gemini interface (reviewer)
â”‚  â”œâ”€ store.py                 # ChromaDB + embeddings
â”‚  â””â”€ io_helpers.py
â”œâ”€ data/
â”‚  â”œâ”€ downloaded/              # Raw scraped files
â”‚  â”œâ”€ outputs/
â”‚  â”‚  â”œâ”€ drafts/               # AI + human drafts
â”‚  â”‚  â”œâ”€ final/                # Final approved drafts
â”‚  â”‚  â””â”€ docs/                 # Prompt history, summaries
â”‚  â””â”€ chroma/                  # Persistent vector store
â””â”€ README.md

âš™ï¸ Setup
1) Install requirements
pip install google-generativeai chromadb sentence-transformers requests beautifulsoup4 python-dotenv

2) Configure environment
3) 
Create .env in project root:
GEMINI_API_KEY=your_google_generative_ai_key
MODEL_NAME=gemini-1.5-pro
EMBED_MODEL=all-MiniLM-L6-v2
CHROMA_DIR=./data/chroma

â–¶ï¸ Usage
A) Scrape + Process a chapter from the web
python main.py \
  --source web \
  --url "https://wikisource.org/your-chapter-url" \
  --title "Chapter 01 - Beginnings"

B) Use a local text/PDF file
python main.py \
  --source file \
  --path "./data/downloaded/chapter01.txt" \
  --title "Chapter 01 - Beginnings"

C) Workflow steps (automated):

Scrape/Load original text â†’ save to data/downloaded/

Initialize ChromaDB (persistent vector store)

AI Writer generates Draft v1

AI Reviewer produces editorial feedback

Human Review: approve or provide edits (CLI prompt)

Final Storage: store final_draft + metadata in ChromaDB and data/outputs/final/

ğŸ§  Prompts

prompts/extraction_prompt.txt â€“ guides structure (headings, summaries, key terms)

prompts/review_prompt.txt â€“ instructs reviewer to compare fidelity, tone, clarity, and suggest edits

ğŸ§¾ Example Console Output
--- Step 1: Scraping content from the web ---
Successfully scraped and read the original chapter text.

--- Step 2: Initializing ChromaDB for versioning ---
Original chapter version stored in ChromaDB.

--- Step 3: AI writing and review cycle ---
AI draft 1 created and stored.

AI Reviewer Feedback:
"The rewritten text flows better but loses some original context in paragraph 2.
Consider restoring the metaphors."

--- Step 4: Human-in-the-Loop review ---
Please provide your edits or 'approve':

ğŸ› ï¸ Troubleshooting

Auth errors: verify GEMINI_API_KEY and network access

Empty scrape: check the URL and update selectors in web_scraper.py

Model errors: switch MODEL_NAME or reduce context length

Chroma issues: delete data/chroma/ to rebuild the store

ğŸ—ºï¸ Roadmap

Multi-draft iteration with scoring

YAML run manifests for full reproducibility

Optional OCR (for scanned PDFs)

Web UI (FastAPI + simple dashboard)

ğŸ™ Acknowledgments

Google Gemini for generative capabilities

ChromaDB for local vector storage

SentenceTransformer for embeddings
